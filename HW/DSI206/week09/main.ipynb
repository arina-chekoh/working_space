{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66673b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "\n",
    "def tokenize_text(s):\n",
    "    \"\"\"\n",
    "    Tokenize the given sentences into a list of words\n",
    "    Input:  s = the input sentence\n",
    "    Output: word tokens\n",
    "    \"\"\"\n",
    "    s_lower = s.lower()\n",
    "    for char in string.whitespace + string.punctuation:\n",
    "        s_lower = s_lower.replace(char, \" \")\n",
    "    tokens = s_lower.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "606666e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_textfile(f):\n",
    "    \"\"\"\n",
    "    Read text file split by new lines\n",
    "    \"\"\"\n",
    "    with open(f, 'r') as f:\n",
    "        return [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1bbf082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bow(tokens, vocab):\n",
    "    \"\"\"\n",
    "    Compute Bag-of-Words representation of the sentence given as word tokens according to the vocabulary\n",
    "    Input:  tokens = a list of word tokens in the sentence\n",
    "            vocab = a list of keywords for creating BoW.\n",
    "    Output: 1D numpy array BoW representation of the sentence\n",
    "    \"\"\"\n",
    "    return np.array([tokens.count(w) for w in vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b541945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(sentence_bow):\n",
    "    \"\"\"\n",
    "    Compute TF of the sentence using log10(count(t,d) + 1) \n",
    "    Input:  sentence_bow = a 1D numpy array BoW representation of the sentence\n",
    "    Output: a 1D numpy array TF of the sentence\n",
    "    \"\"\"\n",
    "    return np.log10(sentence_bow+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb531df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(bow):\n",
    "    \"\"\"\n",
    "    Compute IDF of the corpus using log10(N / dft) \n",
    "    Input:  bow = 2D numpy array BoW representation of all sentences in the corpus\n",
    "    Output: a 1D numpy array IDF of all vocabulary\n",
    "    \"\"\"\n",
    "    N = bow.shape[0]\n",
    "    df = np.sum(bow>0, axis=0)\n",
    "    \n",
    "    return np.log10(N/df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33e43565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2, eps=1e-16):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors\n",
    "    Input:  v1 = vector 1\n",
    "            v2 = vector 2\n",
    "            eps = a constant to avoid zero division\n",
    "    Output: the cosine similarity between vector 1 and vector 2\n",
    "    \"\"\"\n",
    "    return np.dot(v1, v2) / (np.dot(v1,v1)**.5 * np.dot(v2,v2)**.5 + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6f88d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_5(bow, query):\n",
    "    \"\"\"\n",
    "    Find 5 sentences with the highest cosine similarity to the query sentence\n",
    "    Input:  bow = 2D numpy array BoW representation of all sentences in the corpus\n",
    "            query = a 1D array BoW representation of the query sentence\n",
    "    Output: index of the 5 sentences in the corpus with the highest cosine similarity\n",
    "    \"\"\"\n",
    "    num_sentences = bow.shape[0]\n",
    "    score = np.zeros((num_sentences))\n",
    "    for i in range(num_sentences):\n",
    "        score[i] = cosine_similarity(query, bow[i])\n",
    "    return score.argsort()[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eba829d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary =  ['movie', 'film', 'one', 'bad', 'good', 'like', 'acting', 'time', 'really', 'great', 'even', 'see', 'characters', 'well', 'ever', '10', 'movies', 'plot', 'story', 'made', 'best', 'also', 'films', 'character', 'would', 'script', 'seen', 'way', 'love', 'make', 'watching', 'think', 'real', 'could', 'every', 'much', 'work', 'look', 'funny', 'scenes', 'actors', 'better', 'cast', 'never', 'wonderful', 'little', 'watch', 'show', 'everything', 'excellent', 'anyone', 'totally', 'music', 'scene', 'waste', 'people', 'screen', 'go', 'years', 'nothing', 'stupid', 'awful', 'get', 'know', 'still', 'many', 'man', 'art', 'two', 'right', 'say', 'recommend', 'dialogue', 'worth', 'writing', 'pretty', 'thing', 'saw', 'thought', 'life', 'line', 'things', 'interesting', 'director', 'terrible', 'performance', 'enough', 'beautiful', 'short', 'part', 'give', 'worst', 'though', 'first', 'ending', 'end', 'worse', 'black', 'camera', 'find']\n",
      "TFIDF\n",
      "\t Sample sentence 1:  Tenet is such a great great movie that I would recommend everyone to watch this movie.\n",
      "\t Sample sentence 2:  I recommend Mulan if you are looking for a good movie.\n",
      "\t\t cosine similarity between sentence 1 and sentence 2 = 0.471197\n",
      "\t Sample sentence 3:  Twilight is a bad movie. A total waste of time.\n",
      "\t\t cosine similarity between sentence 1 and sentence 3 = 0.085803\n",
      "Top 5 most similar sentences to sentence 1\n",
      "  -  \" with great sound effects, and impressive special effects, i can't recommend this movie enough.\n",
      "  -  this movie is great--especially if you enjoy visual arts.\n",
      "  -  if you want a movie that's not gross but gives you some chills, this is a great choice.\n",
      "  -  great movie!\n",
      "  -  this is just a great movie.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    text_file = 'imdb_data.txt'\n",
    "    vocab_file = 'vocab.txt'\n",
    "\n",
    "    sentences = read_textfile(text_file)\n",
    "    data = [tokenize_text(line) for line in sentences]\n",
    "    vocab = read_textfile(vocab_file)\n",
    "    print('Vocabulary = ', vocab)\n",
    "\n",
    "    # create bag-of-word representation\n",
    "    num_vocabs = len(vocab)\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    bow = np.zeros((num_sentences, num_vocabs))\n",
    "    tf = np.zeros((num_sentences, num_vocabs))\n",
    "    for i in range(num_sentences):\n",
    "        bow[i] = compute_bow(data[i], vocab)\n",
    "        tf[i] = compute_tf(bow[i])\n",
    "    \n",
    "    # Compute IDF\n",
    "    idf = compute_idf(bow)\n",
    "    # compute TFIDF\n",
    "    tfidf = tf * idf\n",
    "\n",
    "    # test cosine similarity\n",
    "    sample_sent1 = 'Tenet is such a great great movie that I would recommend everyone to watch this movie.'\n",
    "    token1 = tokenize_text(sample_sent1)\n",
    "    spl_bow1 = compute_bow(token1, vocab)\n",
    "    tfidf1 = compute_tf(spl_bow1) * idf\n",
    "\n",
    "    # similar sentence\n",
    "    sample_sent2 = 'I recommend Mulan if you are looking for a good movie.'\n",
    "    token2 = tokenize_text(sample_sent2)\n",
    "    spl_bow2 = compute_bow(token2, vocab)\n",
    "    tfidf2 = compute_tf(spl_bow2) * idf\n",
    "\n",
    "    print('TFIDF')\n",
    "    print('\\t Sample sentence 1: ', sample_sent1)\n",
    "    print('\\t Sample sentence 2: ', sample_sent2)\n",
    "    print(f'\\t\\t cosine similarity between sentence 1 and sentence 2 = {cosine_similarity(tfidf1, tfidf2):.6f}')\n",
    "\n",
    "    # dissimilar sentence\n",
    "    sample_sent3 = 'Twilight is a bad movie. A total waste of time.'\n",
    "    token3 = tokenize_text(sample_sent3)\n",
    "    spl_bow3 = compute_bow(token3, vocab)\n",
    "    tfidf3 = compute_tf(spl_bow3) * idf\n",
    "    print('\\t Sample sentence 3: ', sample_sent3)\n",
    "    print(f'\\t\\t cosine similarity between sentence 1 and sentence 3 = {cosine_similarity(tfidf1, tfidf3):.6f}')\n",
    "\n",
    "    # show top 5 most similar sentences in the corpus\n",
    "    print('Top 5 most similar sentences to sentence 1')\n",
    "    top5 = get_top_5(tfidf, tfidf1)\n",
    "    for i in top5:\n",
    "        print('  - ', sentences[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72611d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f4b376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
