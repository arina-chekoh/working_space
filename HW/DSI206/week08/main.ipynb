{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0d5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "\n",
    "def tokenize_text(s):\n",
    "    \"\"\"\n",
    "    Tokenize the given sentences into a list of words\n",
    "    Input:  s = the input sentence\n",
    "    Output: word tokens\n",
    "    \"\"\"\n",
    "    s_lower = s.lower()\n",
    "    for char in string.whitespace + string.punctuation:\n",
    "        s_lower = s_lower.replace(char, \" \")\n",
    "    tokens = s_lower.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7ad164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_textfile(f):\n",
    "    \"\"\"\n",
    "    Read text file split by new lines\n",
    "    \"\"\"\n",
    "    with open(f, 'r') as f:\n",
    "        return [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a210b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bow(tokens, vocab):\n",
    "    \"\"\"\n",
    "    Compute Bag-of-Words representation of the sentence given as word tokens according to the vocabulary\n",
    "    Input:  tokens = a list of word tokens in the sentence\n",
    "            vocab = a list of keywords for creating BoW.\n",
    "    Output: 1D numpy  BoW representation of the sentence\n",
    "    \"\"\"\n",
    "    Bow = []\n",
    "    for n in vocab:\n",
    "        Bow.append(tokens.count(n))\n",
    "    return Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3beb0138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2, eps=1e-16):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors\n",
    "    Input:  v1 = vector 1\n",
    "            v2 = vector 2\n",
    "            eps = a constant to avoid zero division\n",
    "    Output: the cosine similarity between vector 1 and vector 2\n",
    "    \"\"\"\n",
    "    xx, xy, yy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i] \n",
    "        y = v2[i]\n",
    "        xx += x*x\n",
    "        yy += y*y\n",
    "        xy += x*y\n",
    "    \n",
    "    return xy/math.sqrt(xx*yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "338e5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_5(bow, query):\n",
    "    \"\"\"\n",
    "    Find 5 sentences with the highest cosine similarity to the query sentence\n",
    "    Input:  bow = 2D numpy array BoW representation of all sentences in the corpus\n",
    "            query = a 1D array BoW representation of the query sentence\n",
    "    Output: index of the 5 sentences in the corpus with the highest cosine similarity\n",
    "    \"\"\"\n",
    "    num_sentences = bow.shape[0]\n",
    "    score = np.zeros((num_sentences))\n",
    "    for i in range(num_sentences):\n",
    "        score[i] = cosine_similarity(query, bow[i])\n",
    "    return score.argsort()[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b838e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary =  ['movie', 'film', 'one', 'bad', 'good', 'like', 'acting', 'time', 'really', 'great', 'even', 'see', 'characters', 'well', 'ever', '10', 'movies', 'plot', 'story', 'made', 'best', 'also', 'films', 'character', 'would', 'script', 'seen', 'way', 'love', 'make', 'watching', 'think', 'real', 'could', 'every', 'much', 'work', 'look', 'funny', 'scenes', 'actors', 'better', 'cast', 'never', 'wonderful', 'little', 'watch', 'show', 'everything', 'excellent', 'anyone', 'totally', 'music', 'scene', 'waste', 'people', 'screen', 'go', 'years', 'nothing', 'stupid', 'awful', 'get', 'know', 'still', 'many', 'man', 'art', 'two', 'right', 'say', 'recommend', 'dialogue', 'worth', 'writing', 'pretty', 'thing', 'saw', 'thought', 'life', 'line', 'things', 'interesting', 'director', 'terrible', 'performance', 'enough', 'beautiful', 'short', 'part', 'give', 'worst', 'though', 'first', 'ending', 'end', 'worse', 'black', 'camera', 'find']\n",
      "BoW\n",
      "\t Sample sentence 1:  Tenet is such a great great movie that I would recommend everyone to watch this movie.\n",
      "\t Sample sentence 2:  I recommend Mulan if you are looking for a good movie.\n",
      "\t\t cosine similarity between sentence 1 and sentence 2 = 0.522233\n",
      "\t Sample sentence 3:  Twilight is a bad movie. A total waste of time.\n",
      "\t\t cosine similarity between sentence 1 and sentence 3 = 0.301511\n",
      "Top 5 most similar sentences to sentence 1\n",
      "  -  filmiing was less expansive.\n",
      "  -  ray charles is legendary.\n",
      "  -  generally; it just lacked imagination.\n",
      "  -  he's a national treasure.\n",
      "  -  there is simply no excuse for something this poorly done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\dsi206\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    text_file = 'imdb_data.txt'\n",
    "    vocab_file = 'vocab.txt'\n",
    "\n",
    "    sentences = read_textfile(text_file)\n",
    "    data = [tokenize_text(line) for line in sentences]\n",
    "    vocab = read_textfile(vocab_file)\n",
    "    print('Vocabulary = ', vocab)\n",
    "\n",
    "    # create bag-of-word representation\n",
    "    num_vocabs = len(vocab)\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    bow = np.zeros((num_sentences, num_vocabs))\n",
    "    for i in range(num_sentences):\n",
    "        bow[i] = compute_bow(data[i], vocab)\n",
    "        \n",
    "     # test cosine similarity\n",
    "    sample_sent1 = 'Tenet is such a great great movie that I would recommend everyone to watch this movie.'\n",
    "    token1 = tokenize_text(sample_sent1)\n",
    "    spl_bow1 = compute_bow(token1, vocab)\n",
    "    \n",
    "    # similar sentence\n",
    "    sample_sent2 = 'I recommend Mulan if you are looking for a good movie.'\n",
    "    token2 = tokenize_text(sample_sent2)\n",
    "    spl_bow2 = compute_bow(token2, vocab)\n",
    "    \n",
    "    print('BoW')\n",
    "    print('\\t Sample sentence 1: ', sample_sent1)\n",
    "    print('\\t Sample sentence 2: ', sample_sent2)\n",
    "    print(f'\\t\\t cosine similarity between sentence 1 and sentence 2 = {cosine_similarity(spl_bow1, spl_bow2):.6f}')\n",
    "    \n",
    "    # dissimilar sentence\n",
    "    sample_sent3 = 'Twilight is a bad movie. A total waste of time.'\n",
    "    token3 = tokenize_text(sample_sent3)\n",
    "    spl_bow3 = compute_bow(token3, vocab)\n",
    "    print('\\t Sample sentence 3: ', sample_sent3)\n",
    "    print(f'\\t\\t cosine similarity between sentence 1 and sentence 3 = {cosine_similarity(spl_bow1, spl_bow3):.6f}')\n",
    "    \n",
    "    # show top 5 most similar sentences in the corpus\n",
    "    print('Top 5 most similar sentences to sentence 1')\n",
    "    top5 = get_top_5(bow, spl_bow1)\n",
    "    for i in top5:\n",
    "        print('  - ', sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d6049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
