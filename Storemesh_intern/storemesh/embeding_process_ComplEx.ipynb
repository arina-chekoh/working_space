{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1deb6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-1.1.5-cp36-cp36m-win_amd64.whl (8.7 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2017.2\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.1.5 pytz-2022.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d6f601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ampligraph\n",
      "  Using cached ampligraph-1.4.0-py3-none-any.whl (168 kB)\n",
      "Collecting recommonmark==0.4.0\n",
      "  Using cached recommonmark-0.4.0-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: pandas>=0.23.1 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from ampligraph) (1.1.5)\n",
      "Collecting sphinxcontrib-bibtex==0.4.2\n",
      "  Using cached sphinxcontrib_bibtex-0.4.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting scikit-learn>=0.19.1\n",
      "  Using cached scikit_learn-0.24.2-cp36-cp36m-win_amd64.whl (6.8 MB)\n",
      "Collecting pyyaml>=3.13\n",
      "  Using cached PyYAML-6.0-cp36-cp36m-win_amd64.whl (153 kB)\n",
      "Collecting sphinx<3,>=2.2\n",
      "  Using cached Sphinx-2.4.5-py3-none-any.whl (2.7 MB)\n",
      "Collecting rdflib>=4.2.2\n",
      "  Using cached rdflib-5.0.0-py3-none-any.whl (231 kB)\n",
      "Collecting beautifultable>=0.7.0\n",
      "  Using cached beautifultable-1.1.0-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: scipy>=1.3.0 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from ampligraph) (1.5.2)\n",
      "Collecting tqdm>=4.23.4\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: numpy>=1.14.3 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from ampligraph) (1.19.2)\n",
      "Collecting flake8>=3.7.7\n",
      "  Using cached flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: setuptools>=36 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from ampligraph) (58.0.4)\n",
      "Collecting networkx>=2.3\n",
      "  Using cached networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting pytest>=3.5.1\n",
      "  Using cached pytest-7.0.1-py3-none-any.whl (296 kB)\n",
      "Collecting sphinx-rtd-theme==0.4.3\n",
      "  Using cached sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl (6.4 MB)\n",
      "Collecting commonmark<=0.5.4\n",
      "  Using cached CommonMark-0.5.4-py3-none-any.whl\n",
      "Collecting docutils>=0.11\n",
      "  Using cached docutils-0.18.1-py2.py3-none-any.whl (570 kB)\n",
      "Collecting pybtex>=0.20\n",
      "  Using cached pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
      "Collecting pybtex-docutils>=0.2.0\n",
      "  Using cached pybtex_docutils-1.0.2-py3-none-any.whl (6.3 kB)\n",
      "Requirement already satisfied: six>=1.4.1 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from sphinxcontrib-bibtex==0.4.2->ampligraph) (1.16.0)\n",
      "Collecting oset>=0.1.3\n",
      "  Using cached oset-0.1.3-py3-none-any.whl\n",
      "Requirement already satisfied: wcwidth in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from beautifultable>=0.7.0->ampligraph) (0.2.5)\n",
      "Collecting mccabe<0.7.0,>=0.6.0\n",
      "  Using cached mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting importlib-metadata<4.3\n",
      "  Using cached importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
      "Collecting pycodestyle<2.9.0,>=2.8.0\n",
      "  Using cached pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
      "Collecting pyflakes<2.5.0,>=2.4.0\n",
      "  Using cached pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from importlib-metadata<4.3->flake8>=3.7.7->ampligraph) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from importlib-metadata<4.3->flake8>=3.7.7->ampligraph) (4.1.1)\n",
      "Collecting decorator<5,>=4.3\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from pandas>=0.23.1->ampligraph) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from pandas>=0.23.1->ampligraph) (2.8.2)\n",
      "Collecting latexcodec>=1.0.4\n",
      "  Using cached latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tomli>=1.0.0\n",
      "  Using cached tomli-1.2.3-py3-none-any.whl (12 kB)\n",
      "Collecting atomicwrites>=1.0\n",
      "  Using cached atomicwrites-1.4.1-py2.py3-none-any.whl\n",
      "Collecting iniconfig\n",
      "  Using cached iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from pytest>=3.5.1->ampligraph) (21.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from pytest>=3.5.1->ampligraph) (21.3)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from pytest>=3.5.1->ampligraph) (0.4.4)\n",
      "Collecting py>=1.8.2\n",
      "  Using cached py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from rdflib>=4.2.2->ampligraph) (3.0.4)\n",
      "Collecting isodate\n",
      "  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting sphinxcontrib-qthelp\n",
      "  Using cached sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
      "Collecting alabaster<0.8,>=0.7\n",
      "  Using cached alabaster-0.7.12-py2.py3-none-any.whl (14 kB)\n",
      "Collecting babel!=2.0,>=1.3\n",
      "  Using cached Babel-2.10.3-py3-none-any.whl (9.5 MB)\n",
      "Collecting sphinxcontrib-applehelp\n",
      "  Using cached sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
      "Collecting sphinxcontrib-devhelp\n",
      "  Using cached sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
      "Collecting sphinxcontrib-serializinghtml\n",
      "  Using cached sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
      "Collecting sphinxcontrib-jsmath\n",
      "  Using cached sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Requirement already satisfied: Jinja2>=2.3 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from sphinx<3,>=2.2->ampligraph) (3.0.3)\n",
      "Collecting imagesize\n",
      "  Using cached imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Collecting snowballstemmer>=1.1\n",
      "  Using cached snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "Collecting sphinxcontrib-htmlhelp\n",
      "  Using cached sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: Pygments>=2.0 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from sphinx<3,>=2.2->ampligraph) (2.11.2)\n",
      "Collecting requests>=2.5.0\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting docutils>=0.11\n",
      "  Using cached docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from Jinja2>=2.3->sphinx<3,>=2.2->ampligraph) (2.0.1)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\.conda\\envs\\oc\\lib\\site-packages (from requests>=2.5.0->sphinx<3,>=2.2->ampligraph) (2021.5.30)\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: urllib3, pyyaml, latexcodec, idna, charset-normalizer, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, snowballstemmer, requests, pybtex, importlib-metadata, imagesize, docutils, babel, alabaster, tomli, threadpoolctl, sphinx, pyflakes, pycodestyle, pybtex-docutils, py, pluggy, oset, mccabe, joblib, isodate, iniconfig, importlib-resources, decorator, commonmark, atomicwrites, tqdm, sphinxcontrib-bibtex, sphinx-rtd-theme, scikit-learn, recommonmark, rdflib, pytest, networkx, flake8, beautifultable, ampligraph\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.8.1\n",
      "    Uninstalling importlib-metadata-4.8.1:\n",
      "      Successfully uninstalled importlib-metadata-4.8.1\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed alabaster-0.7.12 ampligraph-1.4.0 atomicwrites-1.4.1 babel-2.10.3 beautifultable-1.1.0 charset-normalizer-2.0.12 commonmark-0.5.4 decorator-4.4.2 docutils-0.17.1 flake8-4.0.1 idna-3.3 imagesize-1.4.1 importlib-metadata-4.2.0 importlib-resources-5.4.0 iniconfig-1.1.1 isodate-0.6.1 joblib-1.1.0 latexcodec-2.0.1 mccabe-0.6.1 networkx-2.5.1 oset-0.1.3 pluggy-1.0.0 py-1.11.0 pybtex-0.24.0 pybtex-docutils-1.0.2 pycodestyle-2.8.0 pyflakes-2.4.0 pytest-7.0.1 pyyaml-6.0 rdflib-5.0.0 recommonmark-0.4.0 requests-2.27.1 scikit-learn-0.24.2 snowballstemmer-2.2.0 sphinx-2.4.5 sphinx-rtd-theme-0.4.3 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-bibtex-0.4.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 threadpoolctl-3.1.0 tomli-1.2.3 tqdm-4.64.0 urllib3-1.26.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ampligraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4151bdc",
   "metadata": {},
   "source": [
    "## IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3e5165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\.conda\\envs\\oc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymssql\n",
    "import pandas as pd\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import ampligraph\n",
    "from ampligraph.datasets import load_from_csv\n",
    "from ampligraph.evaluation import train_test_split_no_unseen\n",
    "from ampligraph.latent_features import ComplEx, HolE, ConvE, TransE\n",
    "from sklearn.model_selection import train_test_split\n",
    "ampligraph.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc8d2f7",
   "metadata": {},
   "source": [
    "## PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2541cbc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/embeding_data5.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0025bb5fcede>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/embeding_data5.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\oc\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\oc\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\oc\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\oc\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\oc\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/embeding_data5.csv'"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('data/embeding_data5.csv', header = 0)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa29cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = load_from_csv('','embeding_data.csv', sep=',')\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb50b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tax_0105532006791</td>\n",
       "      <td>export_to_country</td>\n",
       "      <td>exportcountry_103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tax_0105537143843</td>\n",
       "      <td>export_to_country</td>\n",
       "      <td>exportcountry_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tax_0745559008153</td>\n",
       "      <td>export_to_country</td>\n",
       "      <td>exportcountry_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tax_0115545010695</td>\n",
       "      <td>export_to_country</td>\n",
       "      <td>exportcountry_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tax_0105545014810</td>\n",
       "      <td>export_to_country</td>\n",
       "      <td>exportcountry_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640787</th>\n",
       "      <td>activity_21984</td>\n",
       "      <td>held_on</td>\n",
       "      <td>actprovince_62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640788</th>\n",
       "      <td>activity_23108</td>\n",
       "      <td>held_on</td>\n",
       "      <td>actprovince_62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640789</th>\n",
       "      <td>activity_23259</td>\n",
       "      <td>held_on</td>\n",
       "      <td>actprovince_62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640790</th>\n",
       "      <td>activity_23290</td>\n",
       "      <td>held_on</td>\n",
       "      <td>actprovince_62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640791</th>\n",
       "      <td>activity_23315</td>\n",
       "      <td>held_on</td>\n",
       "      <td>actprovince_62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640792 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  subject          predicate             object\n",
       "0       tax_0105532006791  export_to_country  exportcountry_103\n",
       "1       tax_0105537143843  export_to_country   exportcountry_52\n",
       "2       tax_0745559008153  export_to_country    exportcountry_4\n",
       "3       tax_0115545010695  export_to_country    exportcountry_3\n",
       "4       tax_0105545014810  export_to_country    exportcountry_4\n",
       "...                   ...                ...                ...\n",
       "640787     activity_21984            held_on     actprovince_62\n",
       "640788     activity_23108            held_on     actprovince_62\n",
       "640789     activity_23259            held_on     actprovince_62\n",
       "640790     activity_23290            held_on     actprovince_62\n",
       "640791     activity_23315            held_on     actprovince_62\n",
       "\n",
       "[640792 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('data/embeding_data5.csv')\n",
    "# for col in X:\n",
    "#     X[col] = X[col].astype(str)\n",
    "# X = X.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a482e16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subject, predicate, object]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X['subject'].apply(lambda x : True if type(x)==float else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2644d050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subject, predicate, object]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X['predicate'].apply(lambda x : True if type(x)==float else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "435bb195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>predicate</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subject, predicate, object]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X['object'].apply(lambda x : True if type(x)==float else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e2d130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['tax_0105532006791', 'export_to_country', 'exportcountry_103'],\n",
       "       ['tax_0105537143843', 'export_to_country', 'exportcountry_52'],\n",
       "       ['tax_0745559008153', 'export_to_country', 'exportcountry_4'],\n",
       "       ...,\n",
       "       ['activity_23259', 'held_on', 'actprovince_62'],\n",
       "       ['activity_23290', 'held_on', 'actprovince_62'],\n",
       "       ['activity_23315', 'held_on', 'actprovince_62']], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd24e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9efd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eed101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "305261ba",
   "metadata": {},
   "source": [
    "### unique PREDICATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "931a419f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['based_on', 'export_product', 'export_to_country', 'focus_product',\n",
       "       'held_on', 'join'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations = np.unique(X[1:, 1])\n",
    "relations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4db4b4",
   "metadata": {},
   "source": [
    "### train test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a691236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size:  (480594, 3)\n",
      "Test set size:  (160198, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Train set size: ', X_train.shape)\n",
    "print('Test set size: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe06a0",
   "metadata": {},
   "source": [
    "### define model var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d2d5eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ComplEx(batches_count=100\n",
    "                ,seed=0,epochs=100\n",
    "                ,k=100\n",
    "                ,eta=5\n",
    "                ,optimizer='adam'\n",
    "                ,optimizer_params={'lr':1e-3}\n",
    "                ,loss='multiclass_nll'\n",
    "                ,regularizer='LP'\n",
    "                ,regularizer_params={'p':3, 'lambda':1e-5}\n",
    "                ,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ec331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf. logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d846184",
   "metadata": {},
   "source": [
    "### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "080020b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average ComplEx Loss:   0.051082: 100%|██████████| 100/100 [04:34<00:00,  2.74s/epoch]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, early_stopping = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91169737",
   "metadata": {},
   "source": [
    "### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6b7fc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is fit!\n"
     ]
    }
   ],
   "source": [
    "from ampligraph.latent_features import save_model, restore_model\n",
    "save_model(model, 'output/best_model.pkl')\n",
    "del model\n",
    "model = restore_model('output/best_model.pkl')\n",
    "\n",
    "if model.is_fitted:\n",
    "    print('The model is fit!')\n",
    "else:\n",
    "    print('The model is not fit! Did you skip a step?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937cc5b",
   "metadata": {},
   "source": [
    "### create model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5517132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.utils import create_tensorboard_visualizations\n",
    "create_tensorboard_visualizations(model, os.path.join('output', 'ComplEX_06'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1d43059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113212"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.ent_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504cc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd output/ComplEX_06/\n",
    "tensorboard --logdir=./visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62abe91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7544a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3834eea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
